configs,predicted_perpx
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    240,
    360,
    120,
    120,
    360,
    480,
    480,
    240,
    240,
    240,
    240,
    540
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299962043762207
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    240,
    120,
    540,
    360,
    360,
    360,
    360,
    240,
    120,
    240,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299920082092285
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    240,
    480,
    360,
    480,
    600,
    240,
    120,
    240,
    240,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299885749816895
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    120,
    120,
    360,
    360,
    360,
    240,
    240,
    360,
    480,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299802780151367
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    360,
    120,
    120,
    240,
    360,
    360,
    360,
    240,
    480,
    240,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299789428710938
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    240,
    120,
    360,
    480,
    480,
    240,
    120,
    360,
    480,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299779891967773
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    360,
    120,
    120,
    240,
    480,
    360,
    360,
    240,
    240,
    240,
    600
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.2997407913208
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    360,
    120,
    240,
    240,
    480,
    360,
    360,
    360,
    120,
    240,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299737930297852
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    120,
    120,
    120,
    240,
    360,
    360,
    360,
    360,
    480,
    240,
    600
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.299723625183105
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    240,
    120,
    240,
    480,
    540,
    600,
    240,
    240,
    240,
    480
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",8.29959774017334
