configs,predicted_perpx
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    360,
    120,
    540,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.145011901855469
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    360,
    120,
    360,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.143281936645508
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    240,
    120,
    360,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.13960075378418
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    120,
    120,
    120,
    120,
    240,
    120,
    360,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.109423637390137
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    120,
    120,
    120,
    120,
    240,
    120,
    120,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.104713439941406
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    120,
    120,
    240,
    120,
    240,
    120,
    120,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.10042953491211
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.091341018676758
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    240,
    120,
    540,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.087336540222168
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    120,
    120,
    240,
    120,
    120,
    120,
    120,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.087057113647461
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    120,
    360,
    120,
    240,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",12.07697868347168
