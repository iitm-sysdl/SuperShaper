configs,predicted_perpx
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    600,
    540,
    540,
    600,
    360,
    768,
    768,
    768,
    600,
    768,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699999809265137
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    540,
    600,
    540,
    768,
    540,
    540,
    600,
    768,
    600,
    600,
    600,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699998378753662
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    768,
    540,
    540,
    768,
    768,
    540,
    600,
    768,
    600,
    540,
    540,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699979782104492
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    768,
    600,
    768,
    600,
    600,
    600,
    768,
    600,
    600,
    600,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699978351593018
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    768,
    600,
    768,
    768,
    540,
    540,
    600,
    768,
    600,
    600,
    600,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.6999640464782715
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    768,
    540,
    768,
    768,
    600,
    480,
    540,
    540,
    768,
    768,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699962615966797
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    768,
    600,
    480,
    768,
    360,
    600,
    600,
    768,
    768,
    600,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699961185455322
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    768,
    540,
    540,
    768,
    480,
    540,
    600,
    600,
    600,
    768,
    600,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.69995641708374
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    600,
    600,
    600,
    600,
    768,
    600,
    768,
    480,
    600,
    768,
    768
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699949264526367
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    600,
    600,
    540,
    600,
    768,
    768,
    600,
    768,
    600,
    768,
    480,
    540
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.6.1"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",5.699948310852051
