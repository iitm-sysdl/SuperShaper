configs,predicted_perpx
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    240,
    120,
    360,
    240,
    240,
    360,
    120,
    240,
    240,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.49998950958252
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    240,
    240,
    120,
    240,
    360,
    240,
    240,
    120,
    120,
    240,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499907493591309
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    240,
    120,
    360,
    120,
    240,
    360,
    120,
    120,
    240,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.49990177154541
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    240,
    120,
    240,
    240,
    360,
    120,
    120,
    240,
    120,
    540
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499897956848145
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    120,
    240,
    360,
    360,
    120,
    480,
    240,
    240,
    120,
    120
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499894142150879
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    240,
    240,
    240,
    480,
    120,
    120,
    120,
    360,
    120,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499890327453613
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    120,
    240,
    240,
    120,
    120,
    120,
    240,
    360,
    120,
    600
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.49986743927002
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    360,
    360,
    120,
    120,
    360,
    120,
    240,
    240,
    120,
    120,
    120,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499857902526855
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    240,
    240,
    120,
    360,
    480,
    120,
    360,
    120,
    120,
    120,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.499842643737793
"BertConfig {
  ""architectures"": [
    ""BertForMaskedLM""
  ],
  ""attention_probs_dropout_prob"": 0.1,
  ""classifier_dropout"": null,
  ""gradient_checkpointing"": false,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-12,
  ""max_position_embeddings"": 512,
  ""mixing"": ""bert-bottleneck"",
  ""model_type"": ""bert"",
  ""normalization_type"": ""layer_norm"",
  ""num_attention_heads"": 12,
  ""num_feedforward_networks"": 1,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 0,
  ""position_embedding_type"": ""absolute"",
  ""rewire"": false,
  ""sample_hidden_size"": [
    120,
    120,
    240,
    240,
    240,
    540,
    120,
    120,
    120,
    360,
    240,
    240
  ],
  ""sample_intermediate_size"": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  ""sample_num_attention_heads"": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  ""sample_num_hidden_layers"": 12,
  ""transformers_version"": ""4.10.0.dev0"",
  ""type_vocab_size"": 2,
  ""use_cache"": true,
  ""vocab_size"": 28996
}
",10.49976634979248
